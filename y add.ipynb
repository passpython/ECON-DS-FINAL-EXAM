{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab28955-4528-4bf8-94b6-c1b97373a9e6",
   "metadata": {},
   "source": [
    "# FINAL EXAM OF ECON 5821\n",
    "\n",
    "\n",
    "#### 1155198448 PAN, Qiying\n",
    "\n",
    "#### 1155198430 MA, Xinlan \n",
    "\n",
    "#### 1155207188 Huang, Lisha "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac932ac-192c-4ed6-adae-7ba2c523c9a6",
   "metadata": {},
   "source": [
    "In our final exam, we will go though it the following procedure\n",
    "* data process\n",
    "* AR(1)\n",
    "* LASSO & RIDGE\n",
    "* Random Forest\n",
    "* Gredient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcfdd053-de81-4a78-af83-262e4f2174b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing the package we need in this program\n",
    "if (!require(\"readxl\")) install.packages(\"readxl\")\n",
    "library(readxl)\n",
    "if (!require(\"glmnet\")) install.packages(\"glmnet\")\n",
    "library(glmnet)\n",
    "if (!require(\"caret\")) install.packages(\"caret\")\n",
    "library(readxl)\n",
    "if (!require(\"tidyverse\")) install.packages(\"tidyverse\")\n",
    "library(readxl)\n",
    "if (!require(\"doParallel\")) install.packages(\"doParallel\")\n",
    "library(doParallel)\n",
    "if (!require(\"foreach\")) install.packages(\"foreach\")\n",
    "library(foreach)\n",
    "if (!require(\"gbm\")) install.packages(\"gbm\")\n",
    "library(gbm)\n",
    "if (!require(\"forecast\")) install.packages(\"forecast\")\n",
    "library(forecast)\n",
    "if (!require(\"tseries\")) install.packages(\"tseries\")\n",
    "library(tseries)\n",
    "if (!require(\"ranger\")) install.packages(\"ranger\")\n",
    "library(ranger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d30f271-48e1-46a6-a939-696cffbef79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl <- makeCluster(16)  # Create a parallel cluster with 16 cores\n",
    "registerDoParallel(cl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92819c0c-5c28-4b67-9404-f0ed7318b240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process the data\n",
    "data_train <- read_excel(\"US_PCE_training.xlsx\")\n",
    "# delet the NA value \n",
    "data_train = na.omit(data_train)\n",
    "# delet the row of 'month'\n",
    "data_train = data_train[data_train$month != 'month',]\n",
    "data_train = t(data_train)\n",
    "\n",
    "#  rename the variable to consist with 'xlsx' file\n",
    "colnames(data_train) <- unlist(data_train[1, ])\n",
    "#delet the first row, it the variable name of column\n",
    "data_train <- data_train[-1, ] \n",
    "\n",
    "#head(data_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "692090e8-9203-4ac6-8b3f-ee2df327e643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process the data.   the same procedure of above cell\n",
    "data_score <- read_excel(\"US_PCE_testing_fake.xlsx\")\n",
    "data_score = na.omit(data_score)\n",
    "data_score = data_score[data_score$month != 'month',]\n",
    "data_score = t(data_score)\n",
    "colnames(data_score) <- unlist(data_score[1, ])\n",
    "data_score <- data_score[-1, ] \n",
    "\n",
    "#head(data_score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f86f3736-504a-4009-9183-00d319ec9c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     row col\n",
      "     row col\n"
     ]
    }
   ],
   "source": [
    "#check if  NA exist.\n",
    "na_coords_train <- which(is.na(data_train), arr.ind = TRUE)\n",
    "na_coords_score <- which(is.na(data_score), arr.ind = TRUE)\n",
    "print(na_coords_train)\n",
    "print(na_coords_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28955d03-bac7-4b7e-aee3-74e959f4d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to dataframe format\n",
    "data_train = as.data.frame(data_train)\n",
    "data_score = as.data.frame(data_score)\n",
    "# Convert the data to numeric\n",
    "data_train[] <- lapply(data_train, as.numeric)\n",
    "data_score[] <- lapply(data_score, as.numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d491f44-9a96-4b3d-a38e-ca9497f2221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat copys\n",
    "data_train_copy = data_train\n",
    "data_score_copy = data_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b117bf5-fc79-4ccc-b6a5-05954363f18b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 206</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>inflation</th><th scope=col>New domestic autos</th><th scope=col>New foreign autos</th><th scope=col>New light trucks</th><th scope=col>Net transactions in used autos</th><th scope=col>Used auto margin</th><th scope=col>Employee reimbursement</th><th scope=col>Used light trucks</th><th scope=col>Tires</th><th scope=col>Accessories and parts</th><th scope=col>⋯</th><th scope=col>Nonprofit nursing homes services to households</th><th scope=col>Recreation services to households</th><th scope=col>Education services to households</th><th scope=col>Social services to households</th><th scope=col>Religious organizations' services to households.1</th><th scope=col>Foundations and grantmaking and giving services to households.1</th><th scope=col>Services of social advocacy establishments to households</th><th scope=col>Civic and social organizations' services to households</th><th scope=col>Professional advocacy services to households</th><th scope=col>yt</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>         NA</td><td>37.337</td><td>37.348</td><td>32.438</td><td>22.544</td><td>5.006</td><td>11.596</td><td>25.124</td><td>46.107</td><td>27.263</td><td>⋯</td><td>6.219</td><td> 9.916</td><td>2.964</td><td>13.044</td><td>12.152</td><td>10.908</td><td>12.304</td><td>13.859</td><td>8.770</td><td>         NA</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.011864352</td><td>37.337</td><td>37.348</td><td>32.436</td><td>22.737</td><td>5.083</td><td>11.671</td><td>25.316</td><td>46.026</td><td>27.204</td><td>⋯</td><td>6.271</td><td> 9.986</td><td>2.928</td><td>12.701</td><td>11.911</td><td>10.671</td><td>11.980</td><td>13.494</td><td>8.818</td><td>0.011864352</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.007903056</td><td>37.481</td><td>37.492</td><td>32.559</td><td>23.010</td><td>5.044</td><td>11.742</td><td>25.603</td><td>46.019</td><td>27.268</td><td>⋯</td><td>6.263</td><td>10.070</td><td>2.886</td><td>12.442</td><td>11.711</td><td>10.570</td><td>11.736</td><td>13.219</td><td>8.874</td><td>0.007903056</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.023677987</td><td>37.409</td><td>37.420</td><td>32.493</td><td>23.136</td><td>5.160</td><td>11.746</td><td>25.790</td><td>46.020</td><td>27.329</td><td>⋯</td><td>6.287</td><td>10.176</td><td>2.852</td><td>12.157</td><td>11.502</td><td>10.252</td><td>11.468</td><td>12.917</td><td>8.937</td><td>0.023677987</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.006306247</td><td>37.553</td><td>37.564</td><td>32.616</td><td>23.134</td><td>5.198</td><td>11.751</td><td>25.786</td><td>45.927</td><td>27.337</td><td>⋯</td><td>6.313</td><td>10.241</td><td>2.811</td><td>11.928</td><td>11.285</td><td> 9.977</td><td>11.251</td><td>12.673</td><td>8.939</td><td>0.006306247</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.034625245</td><td>37.625</td><td>37.636</td><td>32.678</td><td>23.343</td><td>5.313</td><td>11.821</td><td>25.978</td><td>45.940</td><td>27.271</td><td>⋯</td><td>6.342</td><td>10.318</td><td>2.777</td><td>11.664</td><td>11.061</td><td> 9.940</td><td>11.000</td><td>12.391</td><td>9.019</td><td>0.034625245</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 206\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & inflation & New domestic autos & New foreign autos & New light trucks & Net transactions in used autos & Used auto margin & Employee reimbursement & Used light trucks & Tires & Accessories and parts & ⋯ & Nonprofit nursing homes services to households & Recreation services to households & Education services to households & Social services to households & Religious organizations' services to households.1 & Foundations and grantmaking and giving services to households.1 & Services of social advocacy establishments to households & Civic and social organizations' services to households & Professional advocacy services to households & yt\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 &          NA & 37.337 & 37.348 & 32.438 & 22.544 & 5.006 & 11.596 & 25.124 & 46.107 & 27.263 & ⋯ & 6.219 &  9.916 & 2.964 & 13.044 & 12.152 & 10.908 & 12.304 & 13.859 & 8.770 &          NA\\\\\n",
       "\t2 & 0.011864352 & 37.337 & 37.348 & 32.436 & 22.737 & 5.083 & 11.671 & 25.316 & 46.026 & 27.204 & ⋯ & 6.271 &  9.986 & 2.928 & 12.701 & 11.911 & 10.671 & 11.980 & 13.494 & 8.818 & 0.011864352\\\\\n",
       "\t3 & 0.007903056 & 37.481 & 37.492 & 32.559 & 23.010 & 5.044 & 11.742 & 25.603 & 46.019 & 27.268 & ⋯ & 6.263 & 10.070 & 2.886 & 12.442 & 11.711 & 10.570 & 11.736 & 13.219 & 8.874 & 0.007903056\\\\\n",
       "\t4 & 0.023677987 & 37.409 & 37.420 & 32.493 & 23.136 & 5.160 & 11.746 & 25.790 & 46.020 & 27.329 & ⋯ & 6.287 & 10.176 & 2.852 & 12.157 & 11.502 & 10.252 & 11.468 & 12.917 & 8.937 & 0.023677987\\\\\n",
       "\t5 & 0.006306247 & 37.553 & 37.564 & 32.616 & 23.134 & 5.198 & 11.751 & 25.786 & 45.927 & 27.337 & ⋯ & 6.313 & 10.241 & 2.811 & 11.928 & 11.285 &  9.977 & 11.251 & 12.673 & 8.939 & 0.006306247\\\\\n",
       "\t6 & 0.034625245 & 37.625 & 37.636 & 32.678 & 23.343 & 5.313 & 11.821 & 25.978 & 45.940 & 27.271 & ⋯ & 6.342 & 10.318 & 2.777 & 11.664 & 11.061 &  9.940 & 11.000 & 12.391 & 9.019 & 0.034625245\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 206\n",
       "\n",
       "| <!--/--> | inflation &lt;dbl&gt; | New domestic autos &lt;dbl&gt; | New foreign autos &lt;dbl&gt; | New light trucks &lt;dbl&gt; | Net transactions in used autos &lt;dbl&gt; | Used auto margin &lt;dbl&gt; | Employee reimbursement &lt;dbl&gt; | Used light trucks &lt;dbl&gt; | Tires &lt;dbl&gt; | Accessories and parts &lt;dbl&gt; | ⋯ ⋯ | Nonprofit nursing homes services to households &lt;dbl&gt; | Recreation services to households &lt;dbl&gt; | Education services to households &lt;dbl&gt; | Social services to households &lt;dbl&gt; | Religious organizations' services to households.1 &lt;dbl&gt; | Foundations and grantmaking and giving services to households.1 &lt;dbl&gt; | Services of social advocacy establishments to households &lt;dbl&gt; | Civic and social organizations' services to households &lt;dbl&gt; | Professional advocacy services to households &lt;dbl&gt; | yt &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 |          NA | 37.337 | 37.348 | 32.438 | 22.544 | 5.006 | 11.596 | 25.124 | 46.107 | 27.263 | ⋯ | 6.219 |  9.916 | 2.964 | 13.044 | 12.152 | 10.908 | 12.304 | 13.859 | 8.770 |          NA |\n",
       "| 2 | 0.011864352 | 37.337 | 37.348 | 32.436 | 22.737 | 5.083 | 11.671 | 25.316 | 46.026 | 27.204 | ⋯ | 6.271 |  9.986 | 2.928 | 12.701 | 11.911 | 10.671 | 11.980 | 13.494 | 8.818 | 0.011864352 |\n",
       "| 3 | 0.007903056 | 37.481 | 37.492 | 32.559 | 23.010 | 5.044 | 11.742 | 25.603 | 46.019 | 27.268 | ⋯ | 6.263 | 10.070 | 2.886 | 12.442 | 11.711 | 10.570 | 11.736 | 13.219 | 8.874 | 0.007903056 |\n",
       "| 4 | 0.023677987 | 37.409 | 37.420 | 32.493 | 23.136 | 5.160 | 11.746 | 25.790 | 46.020 | 27.329 | ⋯ | 6.287 | 10.176 | 2.852 | 12.157 | 11.502 | 10.252 | 11.468 | 12.917 | 8.937 | 0.023677987 |\n",
       "| 5 | 0.006306247 | 37.553 | 37.564 | 32.616 | 23.134 | 5.198 | 11.751 | 25.786 | 45.927 | 27.337 | ⋯ | 6.313 | 10.241 | 2.811 | 11.928 | 11.285 |  9.977 | 11.251 | 12.673 | 8.939 | 0.006306247 |\n",
       "| 6 | 0.034625245 | 37.625 | 37.636 | 32.678 | 23.343 | 5.313 | 11.821 | 25.978 | 45.940 | 27.271 | ⋯ | 6.342 | 10.318 | 2.777 | 11.664 | 11.061 |  9.940 | 11.000 | 12.391 | 9.019 | 0.034625245 |\n",
       "\n"
      ],
      "text/plain": [
       "  inflation   New domestic autos New foreign autos New light trucks\n",
       "1          NA 37.337             37.348            32.438          \n",
       "2 0.011864352 37.337             37.348            32.436          \n",
       "3 0.007903056 37.481             37.492            32.559          \n",
       "4 0.023677987 37.409             37.420            32.493          \n",
       "5 0.006306247 37.553             37.564            32.616          \n",
       "6 0.034625245 37.625             37.636            32.678          \n",
       "  Net transactions in used autos Used auto margin Employee reimbursement\n",
       "1 22.544                         5.006            11.596                \n",
       "2 22.737                         5.083            11.671                \n",
       "3 23.010                         5.044            11.742                \n",
       "4 23.136                         5.160            11.746                \n",
       "5 23.134                         5.198            11.751                \n",
       "6 23.343                         5.313            11.821                \n",
       "  Used light trucks Tires  Accessories and parts ⋯\n",
       "1 25.124            46.107 27.263                ⋯\n",
       "2 25.316            46.026 27.204                ⋯\n",
       "3 25.603            46.019 27.268                ⋯\n",
       "4 25.790            46.020 27.329                ⋯\n",
       "5 25.786            45.927 27.337                ⋯\n",
       "6 25.978            45.940 27.271                ⋯\n",
       "  Nonprofit nursing homes services to households\n",
       "1 6.219                                         \n",
       "2 6.271                                         \n",
       "3 6.263                                         \n",
       "4 6.287                                         \n",
       "5 6.313                                         \n",
       "6 6.342                                         \n",
       "  Recreation services to households Education services to households\n",
       "1  9.916                            2.964                           \n",
       "2  9.986                            2.928                           \n",
       "3 10.070                            2.886                           \n",
       "4 10.176                            2.852                           \n",
       "5 10.241                            2.811                           \n",
       "6 10.318                            2.777                           \n",
       "  Social services to households\n",
       "1 13.044                       \n",
       "2 12.701                       \n",
       "3 12.442                       \n",
       "4 12.157                       \n",
       "5 11.928                       \n",
       "6 11.664                       \n",
       "  Religious organizations' services to households.1\n",
       "1 12.152                                           \n",
       "2 11.911                                           \n",
       "3 11.711                                           \n",
       "4 11.502                                           \n",
       "5 11.285                                           \n",
       "6 11.061                                           \n",
       "  Foundations and grantmaking and giving services to households.1\n",
       "1 10.908                                                         \n",
       "2 10.671                                                         \n",
       "3 10.570                                                         \n",
       "4 10.252                                                         \n",
       "5  9.977                                                         \n",
       "6  9.940                                                         \n",
       "  Services of social advocacy establishments to households\n",
       "1 12.304                                                  \n",
       "2 11.980                                                  \n",
       "3 11.736                                                  \n",
       "4 11.468                                                  \n",
       "5 11.251                                                  \n",
       "6 11.000                                                  \n",
       "  Civic and social organizations' services to households\n",
       "1 13.859                                                \n",
       "2 13.494                                                \n",
       "3 13.219                                                \n",
       "4 12.917                                                \n",
       "5 12.673                                                \n",
       "6 12.391                                                \n",
       "  Professional advocacy services to households yt         \n",
       "1 8.770                                                 NA\n",
       "2 8.818                                        0.011864352\n",
       "3 8.874                                        0.007903056\n",
       "4 8.937                                        0.023677987\n",
       "5 8.939                                        0.006306247\n",
       "6 9.019                                        0.034625245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将PCE处理成通胀\n",
    "data_train = data_train_copy\n",
    "data_score = data_score_copy \n",
    "\n",
    "data_score = rbind(tail(data_train,1),data_score)\n",
    "\n",
    "#计算inflation\n",
    "data_train$inflation = (log(data_train$`Personal consumption expenditures`)-log(lag(data_train$`Personal consumption expenditures`)))*12\n",
    "data_score$inflation = (log(data_score$`Personal consumption expenditures`)-log(lag(data_score$`Personal consumption expenditures`)))*12\n",
    "#删除原变量\n",
    "data_train = data_train[, !names(data_train) %in% \"Personal consumption expenditures\"]\n",
    "data_score = data_score[, !names(data_score) %in% \"Personal consumption expenditures\"]\n",
    "#移动最后一列到第一列\n",
    "data_train <- data_train[, c(ncol(data_train), 1:(ncol(data_train)-1))]\n",
    "data_score <- data_score[, c(ncol(data_score), 1:(ncol(data_score)-1))]\n",
    "#删除第一个空观测值 \n",
    "data_train$yt = data_train$inflation\n",
    "data_score$yt = data_score$inflation\n",
    "data_score = data_score[-1,]\n",
    "head(data_train)\n",
    "#head(data_score)\n",
    "#tail(data_train)\n",
    "#tail(data_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe4b94-3e86-4b02-b2ec-ac07d5ac8aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c57d28c3-e77c-483b-b1f0-caf5f2e60724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  row col\n",
      "1   1   1\n",
      "1   1 206\n"
     ]
    }
   ],
   "source": [
    "print(which(is.na(data_train), arr.ind = TRUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005bf536-dace-428b-9102-6b9381c577fa",
   "metadata": {},
   "source": [
    "the following cells is to process the data that need for 1 month predition, 3 month predition and 12 month prediction<br>Sorry for not streamlining the code by defining functions, which resulted in a lot of repetition in the subsequent parts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e35bc1a-d529-4168-9d59-4862f1e25f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data preparation for 1 month prediction\n",
    "data_train_1 = data_train\n",
    "data_score_1 = rbind(tail(data_train_1,1),data_score)   \n",
    "\n",
    "data_train_1$inflation = lead(data_train_1$inflation,1) \n",
    "data_score_1$inflation = lead(data_score_1$inflation,1) \n",
    "\n",
    "data_train_1 <- data_train_1[1:(nrow(data_train_1) - 1), ]\n",
    "data_score_1 <- data_score_1[1:(nrow(data_score_1) - 1), ]\n",
    "data_train_1 = data_train_1[-1,]\n",
    "#head(data_train_1)\n",
    "#head(data_score_1)\n",
    "#tail(data_train_1)\n",
    "#tail(data_score_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5a6404-e480-44c7-8c72-785e21887879",
   "metadata": {},
   "source": [
    "this excel simply shows the processed data for one month prediction\n",
    "| Dependent Variable Y| Independent variable X1 |\n",
    "|---------|---------|\n",
    "| \\$Y_{t+1}\\$ | \\$X_t\\$ | \n",
    "| \\$Y_{t+2}\\$ | \\$X_{t+1}\\$ |  \n",
    "\n",
    "where  \\$Y_{t+1}\\$ stand for inflation in period t+1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b0d77cc-7170-4a32-b643-9d25305ec2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 206</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>inflation</th><th scope=col>New domestic autos</th><th scope=col>New foreign autos</th><th scope=col>New light trucks</th><th scope=col>Net transactions in used autos</th><th scope=col>Used auto margin</th><th scope=col>Employee reimbursement</th><th scope=col>Used light trucks</th><th scope=col>Tires</th><th scope=col>Accessories and parts</th><th scope=col>⋯</th><th scope=col>Nonprofit nursing homes services to households</th><th scope=col>Recreation services to households</th><th scope=col>Education services to households</th><th scope=col>Social services to households</th><th scope=col>Religious organizations' services to households.1</th><th scope=col>Foundations and grantmaking and giving services to households.1</th><th scope=col>Services of social advocacy establishments to households</th><th scope=col>Civic and social organizations' services to households</th><th scope=col>Professional advocacy services to households</th><th scope=col>yt</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>0.006306247</td><td>37.337</td><td>37.348</td><td>32.436</td><td>22.737</td><td>5.083</td><td>11.671</td><td>25.316</td><td>46.026</td><td>27.204</td><td>⋯</td><td>6.271</td><td> 9.986</td><td>2.928</td><td>12.701</td><td>11.911</td><td>10.671</td><td>11.980</td><td>13.494</td><td>8.818</td><td>0.011864352</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.034625245</td><td>37.481</td><td>37.492</td><td>32.559</td><td>23.010</td><td>5.044</td><td>11.742</td><td>25.603</td><td>46.019</td><td>27.268</td><td>⋯</td><td>6.263</td><td>10.070</td><td>2.886</td><td>12.442</td><td>11.711</td><td>10.570</td><td>11.736</td><td>13.219</td><td>8.874</td><td>0.007903056</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.025119392</td><td>37.409</td><td>37.420</td><td>32.493</td><td>23.136</td><td>5.160</td><td>11.746</td><td>25.790</td><td>46.020</td><td>27.329</td><td>⋯</td><td>6.287</td><td>10.176</td><td>2.852</td><td>12.157</td><td>11.502</td><td>10.252</td><td>11.468</td><td>12.917</td><td>8.937</td><td>0.023677987</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.017239131</td><td>37.553</td><td>37.564</td><td>32.616</td><td>23.134</td><td>5.198</td><td>11.751</td><td>25.786</td><td>45.927</td><td>27.337</td><td>⋯</td><td>6.313</td><td>10.241</td><td>2.811</td><td>11.928</td><td>11.285</td><td> 9.977</td><td>11.251</td><td>12.673</td><td>8.939</td><td>0.006306247</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.031280565</td><td>37.625</td><td>37.636</td><td>32.678</td><td>23.343</td><td>5.313</td><td>11.821</td><td>25.978</td><td>45.940</td><td>27.271</td><td>⋯</td><td>6.342</td><td>10.318</td><td>2.777</td><td>11.664</td><td>11.061</td><td> 9.940</td><td>11.000</td><td>12.391</td><td>9.019</td><td>0.034625245</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>0.028862106</td><td>37.625</td><td>37.636</td><td>32.678</td><td>23.811</td><td>5.352</td><td>11.813</td><td>26.463</td><td>46.110</td><td>26.932</td><td>⋯</td><td>6.373</td><td>10.407</td><td>2.781</td><td>11.665</td><td>11.141</td><td> 9.917</td><td>10.998</td><td>12.388</td><td>9.095</td><td>0.025119392</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 206\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & inflation & New domestic autos & New foreign autos & New light trucks & Net transactions in used autos & Used auto margin & Employee reimbursement & Used light trucks & Tires & Accessories and parts & ⋯ & Nonprofit nursing homes services to households & Recreation services to households & Education services to households & Social services to households & Religious organizations' services to households.1 & Foundations and grantmaking and giving services to households.1 & Services of social advocacy establishments to households & Civic and social organizations' services to households & Professional advocacy services to households & yt\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t2 & 0.006306247 & 37.337 & 37.348 & 32.436 & 22.737 & 5.083 & 11.671 & 25.316 & 46.026 & 27.204 & ⋯ & 6.271 &  9.986 & 2.928 & 12.701 & 11.911 & 10.671 & 11.980 & 13.494 & 8.818 & 0.011864352\\\\\n",
       "\t3 & 0.034625245 & 37.481 & 37.492 & 32.559 & 23.010 & 5.044 & 11.742 & 25.603 & 46.019 & 27.268 & ⋯ & 6.263 & 10.070 & 2.886 & 12.442 & 11.711 & 10.570 & 11.736 & 13.219 & 8.874 & 0.007903056\\\\\n",
       "\t4 & 0.025119392 & 37.409 & 37.420 & 32.493 & 23.136 & 5.160 & 11.746 & 25.790 & 46.020 & 27.329 & ⋯ & 6.287 & 10.176 & 2.852 & 12.157 & 11.502 & 10.252 & 11.468 & 12.917 & 8.937 & 0.023677987\\\\\n",
       "\t5 & 0.017239131 & 37.553 & 37.564 & 32.616 & 23.134 & 5.198 & 11.751 & 25.786 & 45.927 & 27.337 & ⋯ & 6.313 & 10.241 & 2.811 & 11.928 & 11.285 &  9.977 & 11.251 & 12.673 & 8.939 & 0.006306247\\\\\n",
       "\t6 & 0.031280565 & 37.625 & 37.636 & 32.678 & 23.343 & 5.313 & 11.821 & 25.978 & 45.940 & 27.271 & ⋯ & 6.342 & 10.318 & 2.777 & 11.664 & 11.061 &  9.940 & 11.000 & 12.391 & 9.019 & 0.034625245\\\\\n",
       "\t7 & 0.028862106 & 37.625 & 37.636 & 32.678 & 23.811 & 5.352 & 11.813 & 26.463 & 46.110 & 26.932 & ⋯ & 6.373 & 10.407 & 2.781 & 11.665 & 11.141 &  9.917 & 10.998 & 12.388 & 9.095 & 0.025119392\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 206\n",
       "\n",
       "| <!--/--> | inflation &lt;dbl&gt; | New domestic autos &lt;dbl&gt; | New foreign autos &lt;dbl&gt; | New light trucks &lt;dbl&gt; | Net transactions in used autos &lt;dbl&gt; | Used auto margin &lt;dbl&gt; | Employee reimbursement &lt;dbl&gt; | Used light trucks &lt;dbl&gt; | Tires &lt;dbl&gt; | Accessories and parts &lt;dbl&gt; | ⋯ ⋯ | Nonprofit nursing homes services to households &lt;dbl&gt; | Recreation services to households &lt;dbl&gt; | Education services to households &lt;dbl&gt; | Social services to households &lt;dbl&gt; | Religious organizations' services to households.1 &lt;dbl&gt; | Foundations and grantmaking and giving services to households.1 &lt;dbl&gt; | Services of social advocacy establishments to households &lt;dbl&gt; | Civic and social organizations' services to households &lt;dbl&gt; | Professional advocacy services to households &lt;dbl&gt; | yt &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 2 | 0.006306247 | 37.337 | 37.348 | 32.436 | 22.737 | 5.083 | 11.671 | 25.316 | 46.026 | 27.204 | ⋯ | 6.271 |  9.986 | 2.928 | 12.701 | 11.911 | 10.671 | 11.980 | 13.494 | 8.818 | 0.011864352 |\n",
       "| 3 | 0.034625245 | 37.481 | 37.492 | 32.559 | 23.010 | 5.044 | 11.742 | 25.603 | 46.019 | 27.268 | ⋯ | 6.263 | 10.070 | 2.886 | 12.442 | 11.711 | 10.570 | 11.736 | 13.219 | 8.874 | 0.007903056 |\n",
       "| 4 | 0.025119392 | 37.409 | 37.420 | 32.493 | 23.136 | 5.160 | 11.746 | 25.790 | 46.020 | 27.329 | ⋯ | 6.287 | 10.176 | 2.852 | 12.157 | 11.502 | 10.252 | 11.468 | 12.917 | 8.937 | 0.023677987 |\n",
       "| 5 | 0.017239131 | 37.553 | 37.564 | 32.616 | 23.134 | 5.198 | 11.751 | 25.786 | 45.927 | 27.337 | ⋯ | 6.313 | 10.241 | 2.811 | 11.928 | 11.285 |  9.977 | 11.251 | 12.673 | 8.939 | 0.006306247 |\n",
       "| 6 | 0.031280565 | 37.625 | 37.636 | 32.678 | 23.343 | 5.313 | 11.821 | 25.978 | 45.940 | 27.271 | ⋯ | 6.342 | 10.318 | 2.777 | 11.664 | 11.061 |  9.940 | 11.000 | 12.391 | 9.019 | 0.034625245 |\n",
       "| 7 | 0.028862106 | 37.625 | 37.636 | 32.678 | 23.811 | 5.352 | 11.813 | 26.463 | 46.110 | 26.932 | ⋯ | 6.373 | 10.407 | 2.781 | 11.665 | 11.141 |  9.917 | 10.998 | 12.388 | 9.095 | 0.025119392 |\n",
       "\n"
      ],
      "text/plain": [
       "  inflation   New domestic autos New foreign autos New light trucks\n",
       "2 0.006306247 37.337             37.348            32.436          \n",
       "3 0.034625245 37.481             37.492            32.559          \n",
       "4 0.025119392 37.409             37.420            32.493          \n",
       "5 0.017239131 37.553             37.564            32.616          \n",
       "6 0.031280565 37.625             37.636            32.678          \n",
       "7 0.028862106 37.625             37.636            32.678          \n",
       "  Net transactions in used autos Used auto margin Employee reimbursement\n",
       "2 22.737                         5.083            11.671                \n",
       "3 23.010                         5.044            11.742                \n",
       "4 23.136                         5.160            11.746                \n",
       "5 23.134                         5.198            11.751                \n",
       "6 23.343                         5.313            11.821                \n",
       "7 23.811                         5.352            11.813                \n",
       "  Used light trucks Tires  Accessories and parts ⋯\n",
       "2 25.316            46.026 27.204                ⋯\n",
       "3 25.603            46.019 27.268                ⋯\n",
       "4 25.790            46.020 27.329                ⋯\n",
       "5 25.786            45.927 27.337                ⋯\n",
       "6 25.978            45.940 27.271                ⋯\n",
       "7 26.463            46.110 26.932                ⋯\n",
       "  Nonprofit nursing homes services to households\n",
       "2 6.271                                         \n",
       "3 6.263                                         \n",
       "4 6.287                                         \n",
       "5 6.313                                         \n",
       "6 6.342                                         \n",
       "7 6.373                                         \n",
       "  Recreation services to households Education services to households\n",
       "2  9.986                            2.928                           \n",
       "3 10.070                            2.886                           \n",
       "4 10.176                            2.852                           \n",
       "5 10.241                            2.811                           \n",
       "6 10.318                            2.777                           \n",
       "7 10.407                            2.781                           \n",
       "  Social services to households\n",
       "2 12.701                       \n",
       "3 12.442                       \n",
       "4 12.157                       \n",
       "5 11.928                       \n",
       "6 11.664                       \n",
       "7 11.665                       \n",
       "  Religious organizations' services to households.1\n",
       "2 11.911                                           \n",
       "3 11.711                                           \n",
       "4 11.502                                           \n",
       "5 11.285                                           \n",
       "6 11.061                                           \n",
       "7 11.141                                           \n",
       "  Foundations and grantmaking and giving services to households.1\n",
       "2 10.671                                                         \n",
       "3 10.570                                                         \n",
       "4 10.252                                                         \n",
       "5  9.977                                                         \n",
       "6  9.940                                                         \n",
       "7  9.917                                                         \n",
       "  Services of social advocacy establishments to households\n",
       "2 11.980                                                  \n",
       "3 11.736                                                  \n",
       "4 11.468                                                  \n",
       "5 11.251                                                  \n",
       "6 11.000                                                  \n",
       "7 10.998                                                  \n",
       "  Civic and social organizations' services to households\n",
       "2 13.494                                                \n",
       "3 13.219                                                \n",
       "4 12.917                                                \n",
       "5 12.673                                                \n",
       "6 12.391                                                \n",
       "7 12.388                                                \n",
       "  Professional advocacy services to households yt         \n",
       "2 8.818                                        0.011864352\n",
       "3 8.874                                        0.007903056\n",
       "4 8.937                                        0.023677987\n",
       "5 8.939                                        0.006306247\n",
       "6 9.019                                        0.034625245\n",
       "7 9.095                                        0.025119392"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data preparation for 3 month prediction.    Duplicated\n",
    "data_train_3 = data_train\n",
    "data_score_3 = rbind(tail(data_train_3,3),data_score)\n",
    "\n",
    "data_train_3$inflation = lead(data_train_3$inflation,3) \n",
    "data_score_3$inflation = lead(data_score_3$inflation,3) \n",
    "\n",
    "data_train_3 <- data_train_3[1:(nrow(data_train_3) - 3), ]\n",
    "data_score_3 <- data_score_3[1:(nrow(data_score_3) - 3), ]\n",
    "data_train_3 = data_train_3[-1,]\n",
    "head(data_train_3)\n",
    "#head(data_score_3)\n",
    "#tail(data_train_3)\n",
    "#tail(data_score_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d73822b6-ae4b-4463-bc9b-aec8818bd649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data preparation for 12 month prediction.    Duplicated\n",
    "data_train_12 = data_train\n",
    "data_score_12 = rbind(tail(data_train_12,12),data_score)\n",
    "\n",
    "data_train_12$inflation = lead(data_train_12$inflation,12) \n",
    "data_score_12$inflation = lead(data_score_12$inflation,12) \n",
    "\n",
    "data_train_12 <- data_train_12[1:(nrow(data_train_12) - 12), ]\n",
    "data_score_12 <- data_score_12[1:(nrow(data_score_12) - 12), ]\n",
    "data_train_12 = data_train_12[-1,]\n",
    "#head(data_train_12)\n",
    "#head(data_score_12)\n",
    "#tail(data_train_12)\n",
    "#tail(data_score_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6a2cd6-f88f-4759-8b3d-111d40ec9e3c",
   "metadata": {},
   "source": [
    "the following cells firstlly seperate the data to 70% train data and 30% test data.  then we also seperate the Y and X.<br> \n",
    "train 1 stand for 70% train data, test stand for 30% test data. score stand for real data post on May 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5096c3f1-3d5a-4c88-b4dc-0ff901c1455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data and test data preparation     1 month predition\n",
    "set.seed(123)  \n",
    "train_size_1 <- floor(0.7 * nrow(data_train_1))\n",
    "\n",
    "# Because it's time-series data, we split the training and testing sets directly based on sequence.\n",
    "train_data_1 <- data_train_1[1:train_size_1, ]\n",
    "test_data_1 <- data_train_1[(train_size_1 + 1):nrow(data_train_1), ]\n",
    "\n",
    "\n",
    "train_x_1 <- data.matrix(train_data_1[,-1])  \n",
    "train_y_1 <- train_data_1[,1]\n",
    "\n",
    "test_x_1 <- data.matrix(test_data_1[,-1])\n",
    "test_y_1 <- test_data_1[,1]\n",
    "\n",
    "score_x_1 <- data.matrix(data_score_1[,-1])\n",
    "score_y_1 <- data_score_1[,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "537beab9-9729-4c08-8687-678c0d3273eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data and test data preparation     3 month predition\n",
    "train_size_3 <- floor(0.7 * nrow(data_train_3))\n",
    "\n",
    "# Because it's time-series data, we split the training and testing sets directly based on sequence.\n",
    "train_data_3 <- data_train_3[1:train_size_3, ]\n",
    "test_data_3 <- data_train_3[(train_size_3 + 1):nrow(data_train_3), ]\n",
    "\n",
    "\n",
    "train_x_3 <- data.matrix(train_data_3[,-1])  \n",
    "train_y_3 <- train_data_3[,1]\n",
    "\n",
    "test_x_3 <- data.matrix(test_data_3[,-1])\n",
    "test_y_3 <- test_data_3[,1]\n",
    "\n",
    "score_x_3 <- data.matrix(data_score_3[,-1])\n",
    "score_y_3 <- data_score_3[,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2641fa9-73a5-4200-86d9-9de9bde849c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data and test data preparation     12 month predition\n",
    "train_size_12 <- floor(0.7 * nrow(data_train_12))\n",
    "\n",
    "# Because it's time-series data, we split the training and testing sets directly based on sequence.\n",
    "train_data_12 <- data_train_12[1:train_size_12, ]\n",
    "test_data_12 <- data_train_12[(train_size_12 + 1):nrow(data_train_12), ]\n",
    "\n",
    "\n",
    "train_x_12 <- data.matrix(train_data_12[,-1])  \n",
    "train_y_12 <- train_data_12[,1]\n",
    "\n",
    "test_x_12 <- data.matrix(test_data_12[,-1])\n",
    "test_y_12 <- test_data_12[,1]\n",
    "\n",
    "score_x_12 <- data.matrix(data_score_12[,-1])\n",
    "score_y_12 <- data_score_12[,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6c92e-8f64-47dc-9ad9-c843cf993a70",
   "metadata": {},
   "source": [
    "# AR(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939f246-a35d-40c2-bbc4-358f99036f2c",
   "metadata": {},
   "source": [
    "the following code show AR(1) model of 1 month predition, 3 month predition and 12 month predition.<br>\n",
    "we simply use OLS method to estimate this model.\n",
    "$$Y_t = c + \\phi_1 Y_{t-1} + \\epsilon_t$$\r",
    "in order to compare with the other meshine learning methods, we only use 70% train data to estimate this model. then we use this \"trained\" model to predict the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "077b386c-c1f9-4c52-a275-6fe91b07852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the 70% train data (one month prediction):  0.000378794438041514\"\n",
      "[1] \"MSE of the rest 30% data (one month prediction):  0.000577229495917976\"\n",
      "[1] \"MSE of the real test data (one month prediction):  78.2171299183431\"\n"
     ]
    }
   ],
   "source": [
    "# 1 month prediction of AR(1)\n",
    "train_y = train_y_1\n",
    "test_y = test_y_1\n",
    "score_y = score_y_1\n",
    "\n",
    "# train the AR(1) model using 70% train data\n",
    "ar_model = lm(train_y[-1] ~ lag(train_y)[-1])\n",
    "\n",
    "\n",
    "# train mse\n",
    "prediction = numeric(length(lag(train_y)[-1]))   #Initialize a list to store each predicted value yt\n",
    "train_y_ar = lag(train_y)[-1]\n",
    "for (i in 1:length(lag(train_y)[-1])) {\n",
    "  prediction[i] = coef(ar_model)[1]+coef(ar_model)[2]*train_y_ar[i]\n",
    "}\n",
    "\n",
    "MSE = mean((prediction - train_y[-1])^2) \n",
    "print(paste(\"MSE of the 70% train data (one month prediction): \", MSE))\n",
    "\n",
    "# test mse\n",
    "prediction = numeric(length(test_y))   #Initialize a list to store each predicted value yt\n",
    "test_y_ar = c(tail(train_y,1),test_y[-length(test_y)])\n",
    "for (i in 1:length(test_y)) {\n",
    "  prediction[i] = coef(ar_model)[1]+coef(ar_model)[2]*test_y_ar[i]\n",
    "}\n",
    "\n",
    "MSE = mean((prediction - test_y)^2) # MSE of test data\n",
    "print(paste(\"MSE of the rest 30% data (one month prediction): \", MSE))\n",
    "\n",
    "\n",
    "#score mse\n",
    "prediction_score = numeric(length(score_y))   # MSE of score data\n",
    "score_y_ar = c(tail(test_y,1),score_y[-length(score_y)])\n",
    "for (i in 1:length(score_y)) {\n",
    "  prediction_score[i] = coef(ar_model)[1]+coef(ar_model)[2]*score_y_ar[i]\n",
    "}\n",
    "\n",
    "MSE = mean((prediction_score - score_y)^2)\n",
    "print(paste(\"MSE of the real test data (one month prediction): \", MSE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3f64db4-56f7-4d3e-a681-7a6f524e9bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the 70% train data (three month prediction):  0.000488677768046148\"\n",
      "[1] \"MSE of the rest 30% data (three month prediction):  0.000957063522439213\"\n",
      "[1] \"MSE of the real test data (three month prediction):  49.2549575012447\"\n"
     ]
    }
   ],
   "source": [
    "# 3 month prediction of AR(1)\n",
    "#NOTE:  AR(1) only use dependent value, thus we let  'train_y = train_y_1 '   and then implement \"lag(train_y,3)\" function to estimate 3 month predition AR(1)\n",
    "train_y = train_y_1\n",
    "test_y = test_y_1\n",
    "score_y = score_y_1\n",
    "\n",
    "# train the AR(1) model using 70% train data\n",
    "ar_model = lm(train_y[-(1:3)] ~ lag(train_y,3)[-(1:3)])\n",
    "\n",
    "\n",
    "# train mse\n",
    "prediction = numeric(length(lag(train_y,3)[-(1:3)]))   #Initialize a list to store each predicted value yt\n",
    "train_y_ar = lag(train_y,3)[-(1:3)]\n",
    "for (i in 1:length(lag(train_y,3)[-(1:3)])) {\n",
    "  prediction[i] = coef(ar_model)[1]+coef(ar_model)[2]*train_y_ar[i]\n",
    "}\n",
    "\n",
    "MSE = mean((prediction - train_y[-(1:3)])^2) \n",
    "print(paste(\"MSE of the 70% train data (three month prediction): \", MSE))\n",
    "\n",
    "\n",
    "# test mse\n",
    "prediction = numeric(length(test_y))\n",
    "test_y_ar = c(tail(train_y,3),test_y[1:(length(test_y)-3)])\n",
    "for (i in 1:length(test_y)) {\n",
    "  prediction[i] = coef(ar_model)[1]+coef(ar_model)[2]*test_y_ar[i]\n",
    "}\n",
    "\n",
    "MSE = mean((prediction - test_y)^2)\n",
    "print(paste(\"MSE of the rest 30% data (three month prediction): \", MSE))\n",
    "\n",
    "\n",
    "#score mse\n",
    "prediction_score = numeric(length(score_y))\n",
    "score_y_ar = c(tail(test_y,3),score_y[1:(length(score_y)-3)])\n",
    "for (i in 1:length(score_y)) {\n",
    "  prediction_score[i] = coef(ar_model)[1]+coef(ar_model)[2]*score_y_ar[i]\n",
    "}\n",
    "\n",
    "MSE = mean((prediction_score - score_y)^2)\n",
    "print(paste(\"MSE of the real test data (three month prediction): \", MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be7c7b9b-ebea-4b95-828d-c5a2a3b6d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the 70% train data (12 month prediction):  0.000574751635870192\"\n",
      "[1] \"MSE of the rest 30% data (12 month prediction):  0.00101029907637994\"\n",
      "[1] \"MSE of the real test data (12 month prediction):  42.0167810877226\"\n"
     ]
    }
   ],
   "source": [
    "# 12 month prediction of AR(1)\n",
    "#NOTE:  AR(1) only use dependent value, thus we let  'train_y = train_y_1 '   and then implement \"lag(train_y,12)\" function to estimate 12 month predition AR(1)\n",
    "train_y = train_y_1\n",
    "test_y = test_y_1\n",
    "score_y = score_y_1\n",
    "\n",
    "# train the AR(1) model using 70% train data\n",
    "ar_model = lm(train_y[-(1:12)] ~ lag(train_y,12)[-(1:12)])\n",
    "\n",
    "\n",
    "# train mse\n",
    "prediction = numeric(length(lag(train_y,12)[-(1:12)]))   #Initialize a list to store each predicted value yt\n",
    "train_y_ar = lag(train_y,12)[-(1:12)]\n",
    "for (i in 1:length(lag(train_y,12)[-(1:12)])) {\n",
    "  prediction[i] = coef(ar_model)[1]+coef(ar_model)[2]*train_y_ar[i]\n",
    "}\n",
    "\n",
    "MSE = mean((prediction - train_y[-(1:12)])^2) \n",
    "print(paste(\"MSE of the 70% train data (12 month prediction): \", MSE))\n",
    "\n",
    "# test mse\n",
    "prediction = numeric(length(test_y))\n",
    "test_y_ar = c(tail(train_y,12),test_y[1:(length(test_y)-12)])\n",
    "for (i in 1:length(test_y)) {\n",
    "  prediction[i] = coef(ar_model)[1]+coef(ar_model)[2]*test_y_ar[i]\n",
    "}\n",
    "\n",
    "MSE = mean((prediction - test_y)^2)\n",
    "print(paste(\"MSE of the rest 30% data (12 month prediction): \", MSE))\n",
    "\n",
    "\n",
    "\n",
    "#score mse\n",
    "prediction_score = numeric(length(score_y))\n",
    "score_y_ar = c(tail(test_y,12),score_y[1:(length(score_y)-12)])\n",
    "for (i in 1:length(score_y)) {\n",
    "  prediction_score[i] = coef(ar_model)[1]+coef(ar_model)[2]*score_y_ar[i]\n",
    "}\n",
    "\n",
    "MSE = mean((prediction_score - score_y)^2)\n",
    "print(paste(\"MSE of the real test data (12 month prediction): \", MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c203bf-0c33-472e-9b7c-96c255d9aa92",
   "metadata": {},
   "source": [
    "## Lasso and Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e0813-09ea-460f-ac56-d2bafd806e04",
   "metadata": {},
   "source": [
    "in this part, we use caret package to help conduct CV for lasso and ridge model. Still,we use 70% train data to train Lasso and Ridge regression model. <br>firstly, we apply CV method to choose best lambda, and use the best lambda to train lasso(Ridge) model. since the data is time series data, we use Sliding Window Cross-Validation<br>then use the trained model to predict test data and score data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc3741ed-95f3-4cc5-a2f6-997fdeb90a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the 70% train data (1 month prediction):  0.000341170935698251\"\n",
      "[1] \"MSE of the rest 30% data (1 month prediction):  0.000876712948271478\"\n",
      "[1] \"MSE of real test data (1 month prediction):  43.6374984471829\"\n"
     ]
    }
   ],
   "source": [
    "# ridge and lasso  model for 1 month prediction\n",
    "train_x = train_x_1\n",
    "train_y = train_y_1\n",
    "test_x = test_x_1\n",
    "test_y = test_y_1\n",
    "score_x=score_x_1\n",
    "score_y = score_y_1\n",
    "\n",
    "train_data = train_data_1\n",
    "test_data = test_data_1\n",
    "data_scoreMSE = data_score_1\n",
    "\n",
    "set.seed(1)\n",
    "# CV to choose best lambda.     Ridge\n",
    "\n",
    "# Sliding Window Cross-Validation\n",
    "train_control <- trainControl(method = \"timeslice\",\n",
    "                              initialWindow = floor(0.7*nrow(train_x)),\n",
    "                              horizon = 12,\n",
    "                              skip = 3,\n",
    "                              fixedWindow = TRUE,\n",
    "                              allowParallel = TRUE)\n",
    "\n",
    "#choose best lambda, alpha = 0 is ridge regression\n",
    "tuneGrid <- expand.grid(\n",
    "  alpha = 0,\n",
    "  lambda = 10^seq(5, -5, length=10)\n",
    ") \n",
    "\n",
    "\n",
    "model <- train(train_x, train_y,\n",
    "               method = \"glmnet\",\n",
    "               tuneGrid = tuneGrid,\n",
    "               trControl = train_control);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ridge.mod = glmnet(train_x, train_y, alpha=0, lambda=model$bestTune$lambda)\n",
    "\n",
    "# train mse\n",
    "ridge.pred <- predict(ridge.mod, newx = train_x )\n",
    "mse <- mean((ridge.pred - train_data[, 1])^2)\n",
    "print(paste(\"MSE of the 70% train data (1 month prediction): \", mse)) \n",
    "\n",
    "# test mse\n",
    "ridge.pred <- predict(ridge.mod, newx = test_x )\n",
    "mse <- mean((ridge.pred - test_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 30% data (1 month prediction): \", mse)) \n",
    "\n",
    "# score mse\n",
    "ridge.pred <- predict(ridge.mod,  newx = score_x )\n",
    "mse_score <- mean((ridge.pred - data_scoreMSE[, 1])^2)\n",
    "print(paste(\"MSE of real test data (1 month prediction): \", mse_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb243053-784b-4cc9-8a93-4de61ef71e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the rest 70% train data (1 month prediction):  0.000312779235611123\"\n",
      "[1] \"MSE of the rest 30% data (1 month prediction):  0.000847007023392567\"\n",
      "[1] \"MSE of real test data (1 month prediction):  56.4119188834437\"\n"
     ]
    }
   ],
   "source": [
    "# CV to choose best lambda.     Lasso\n",
    "\n",
    "# Sliding Window Cross-Validation\n",
    "train_control <- trainControl(method = \"timeslice\",\n",
    "                              initialWindow = floor(0.7*nrow(train_x)),\n",
    "                              horizon = 1,\n",
    "                              skip = 1,\n",
    "                              fixedWindow = TRUE,\n",
    "                              allowParallel = TRUE)\n",
    "\n",
    "#choose best lambda, alpha = 1 is lasso regression\n",
    "tuneGrid <- expand.grid(\n",
    "  alpha = 1,\n",
    "  lambda = 10^seq(2, -5, length=50)\n",
    ") \n",
    "\n",
    "\n",
    "model <- train(train_x, train_y,\n",
    "               method = \"glmnet\",\n",
    "               tuneGrid = tuneGrid,\n",
    "               trControl = train_control);\n",
    "\n",
    "\n",
    "lasso.mod = glmnet(train_x, train_y, alpha=1, lambda=model$bestTune$lambda)\n",
    "\n",
    "# train mse\n",
    "lasso.pred <- predict(lasso.mod, newx = train_x )\n",
    "mse <- mean((lasso.pred - train_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 70% train data (1 month prediction): \", mse)) \n",
    "\n",
    "# test mse\n",
    "lasso.pred <- predict(lasso.mod, newx = test_x )\n",
    "mse <- mean((lasso.pred - test_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 30% data (1 month prediction): \", mse)) \n",
    "\n",
    "# score mse\n",
    "lasso.pred <- predict(lasso.mod,  newx = score_x )\n",
    "mse_score <- mean((lasso.pred - data_scoreMSE[, 1])^2)\n",
    "print(paste(\"MSE of real test data (1 month prediction): \", mse_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b64ad040-cca8-4bb3-ad9a-3bdf69b88cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the 70% train data (3 month prediction):  0.000429040826316357\"\n",
      "[1] \"MSE of the rest 30% data (3 month prediction):  0.000664351851957809\"\n",
      "[1] \"MSE of real test data (3 month prediction):  33.7429132075958\"\n"
     ]
    }
   ],
   "source": [
    "# ridge and lasso  model for 3 month prediction\n",
    "train_x = train_x_3\n",
    "train_y = train_y_3\n",
    "test_x = test_x_3\n",
    "test_y = test_y_3\n",
    "score_x=score_x_3\n",
    "score_y = score_y_3\n",
    "\n",
    "train_data = train_data_3\n",
    "test_data = test_data_3\n",
    "data_scoreMSE = data_score_3\n",
    "\n",
    "\n",
    "# CV to choose best lambda.     Ridge\n",
    "\n",
    "# Sliding Window Cross-Validation\n",
    "train_control <- trainControl(method = \"timeslice\",\n",
    "                              initialWindow = floor(0.7*nrow(train_x)),\n",
    "                              horizon = 1,\n",
    "                              skip = 1,\n",
    "                              fixedWindow = TRUE,\n",
    "                              allowParallel = TRUE)\n",
    "\n",
    "#choose best lambda\n",
    "tuneGrid <- expand.grid(\n",
    "  alpha = 0,   #ridge\n",
    "  lambda = 10^seq(2, -5, length=50)\n",
    ") \n",
    "\n",
    "\n",
    "model <- train(train_x, train_y,\n",
    "               method = \"glmnet\",\n",
    "               tuneGrid = tuneGrid,\n",
    "               trControl = train_control);\n",
    "\n",
    "\n",
    "\n",
    "ridge.mod = glmnet(train_x, train_y, alpha=0, lambda=model$bestTune$lambda)\n",
    "\n",
    "# train mse\n",
    "ridge.pred <- predict(ridge.mod, newx = train_x )\n",
    "mse <- mean((ridge.pred - train_data[, 1])^2)\n",
    "print(paste(\"MSE of the 70% train data (3 month prediction): \", mse)) \n",
    "\n",
    "\n",
    "# test mse\n",
    "ridge.pred <- predict(ridge.mod, newx = test_x )\n",
    "mse <- mean((ridge.pred - test_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 30% data (3 month prediction): \", mse)) \n",
    "\n",
    "\n",
    "# score mse\n",
    "ridge.pred <- predict(ridge.mod,  newx = score_x )\n",
    "mse_score <- mean((ridge.pred - data_scoreMSE[, 1])^2)\n",
    "print(paste(\"MSE of real test data (3 month prediction): \", mse_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ab8b8cc-ffd6-47d7-acaf-f2ea1f4bd0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the rest 70% train data (3 month prediction):  0.000397662311094666\"\n",
      "[1] \"MSE of the rest 30% data (3 month prediction):  0.000953923847315587\"\n",
      "[1] \"MSE of real test data (3 month prediction):  36.940760195847\"\n"
     ]
    }
   ],
   "source": [
    "# CV to choose best lambda.     Lasso\n",
    "\n",
    "# Sliding Window Cross-Validation\n",
    "train_control <- trainControl(method = \"timeslice\",\n",
    "                              initialWindow = floor(0.7*nrow(train_x)),\n",
    "                              horizon = 1,\n",
    "                              skip = 1,\n",
    "                              fixedWindow = TRUE,\n",
    "                              allowParallel = TRUE)\n",
    "\n",
    "# choose best lambda\n",
    "tuneGrid <- expand.grid(\n",
    "  alpha = 1,  #lasso\n",
    "  lambda = 10^seq(2, -5, length=100)\n",
    ") \n",
    "\n",
    "\n",
    "model <- train(train_x, train_y,\n",
    "               method = \"glmnet\",\n",
    "               tuneGrid = tuneGrid,\n",
    "               trControl = train_control);\n",
    "\n",
    "\n",
    "\n",
    "lasso.mod = glmnet(train_x, train_y, alpha=1, lambda=model$bestTune$lambda)\n",
    "\n",
    "# train mse\n",
    "lasso.pred <- predict(lasso.mod, newx = train_x )\n",
    "mse <- mean((lasso.pred - train_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 70% train data (3 month prediction): \", mse)) \n",
    "\n",
    "# test mse\n",
    "lasso.pred <- predict(lasso.mod, newx = test_x )\n",
    "mse <- mean((lasso.pred - test_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 30% data (3 month prediction): \", mse)) \n",
    "\n",
    "# test mse\n",
    "lasso.pred <- predict(lasso.mod,  newx = score_x )\n",
    "mse_score <- mean((lasso.pred - data_scoreMSE[, 1])^2)\n",
    "print(paste(\"MSE of real test data (3 month prediction): \", mse_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a93fa1ff-a076-443b-9770-287e2340fdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the 70% train data (12 month prediction):  0.000447126772261063\"\n",
      "[1] \"MSE of the rest 30% data (12 month prediction):  0.000685415758484775\"\n",
      "[1] \"MSE of real test data (12 month prediction):  32.8410247876629\"\n"
     ]
    }
   ],
   "source": [
    "# ridge and lasso  model for 12 month prediction\n",
    "train_x = train_x_12\n",
    "train_y = train_y_12\n",
    "test_x = test_x_12\n",
    "test_y = test_y_12\n",
    "score_x=score_x_12\n",
    "score_y = score_y_12\n",
    "\n",
    "train_data = train_data_12\n",
    "test_data = test_data_12\n",
    "data_scoreMSE = data_score_12\n",
    "\n",
    "\n",
    "# CV to choose best lambda.    ridge\n",
    "\n",
    "# Sliding Window Cross-Validation\n",
    "train_control <- trainControl(method = \"timeslice\",\n",
    "                              initialWindow = floor(0.7*nrow(train_x)),\n",
    "                              horizon = 1,\n",
    "                              skip = 1,\n",
    "                              fixedWindow = TRUE,\n",
    "                              allowParallel = TRUE)\n",
    "\n",
    "#choose best lambda\n",
    "tuneGrid <- expand.grid(\n",
    "  alpha = 0,  #ridge\n",
    "  lambda = 10^seq(2, -7, length=100)\n",
    ") \n",
    "\n",
    "\n",
    "model <- train(train_x, train_y,\n",
    "               method = \"glmnet\",\n",
    "               tuneGrid = tuneGrid,\n",
    "               trControl = train_control);\n",
    "\n",
    "\n",
    "\n",
    "ridge.mod = glmnet(train_x, train_y, alpha=0, lambda=model$bestTune$lambda)\n",
    "\n",
    "# train mse\n",
    "ridge.pred <- predict(ridge.mod, newx = train_x )\n",
    "mse <- mean((ridge.pred - train_data[, 1])^2)\n",
    "print(paste(\"MSE of the 70% train data (12 month prediction): \", mse)) \n",
    "\n",
    "\n",
    "#test mse\n",
    "ridge.pred <- predict(ridge.mod, newx = test_x )\n",
    "mse <- mean((ridge.pred - test_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 30% data (12 month prediction): \", mse)) \n",
    "\n",
    "\n",
    "#score mse\n",
    "ridge.pred <- predict(ridge.mod,  newx = score_x )\n",
    "mse_score <- mean((ridge.pred - data_scoreMSE[, 1])^2)\n",
    "print(paste(\"MSE of real test data (12 month prediction): \", mse_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8022cae9-3f41-4a94-acb7-c188303418e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the rest 70% train data (12 month prediction):  0.0004482906674266\"\n",
      "[1] \"MSE of the rest 30% data (12 month prediction):  0.00129040162192826\"\n",
      "[1] \"MSE of real test data (12 month prediction):  33.4172495393787\"\n"
     ]
    }
   ],
   "source": [
    "# CV to choose best lambda.    lasso\n",
    "\n",
    "# Sliding Window Cross-Validation\n",
    "train_control <- trainControl(method = \"timeslice\",\n",
    "                              initialWindow = floor(0.7*nrow(train_x)),\n",
    "                              horizon = 1,\n",
    "                              skip = 1,\n",
    "                              fixedWindow = TRUE,\n",
    "                              allowParallel = TRUE)\n",
    "\n",
    "#choose best lambda\n",
    "tuneGrid <- expand.grid(\n",
    "  alpha = 1, #lasso\n",
    "  lambda = 10^seq(2, -7, length=100)\n",
    ") \n",
    "\n",
    "\n",
    "model <- train(train_x, train_y,\n",
    "               method = \"glmnet\",\n",
    "               tuneGrid = tuneGrid,\n",
    "               trControl = train_control);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lasso.mod = glmnet(train_x, train_y, alpha=1, lambda=model$bestTune$lambda)\n",
    "\n",
    "# train mse\n",
    "lasso.pred <- predict(lasso.mod, newx = train_x )\n",
    "mse <- mean((lasso.pred - train_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 70% train data (12 month prediction): \", mse)) \n",
    "\n",
    "#test mse\n",
    "lasso.pred <- predict(lasso.mod, newx = test_x )\n",
    "mse <- mean((lasso.pred - test_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 30% data (12 month prediction): \", mse)) \n",
    "\n",
    "# score mse\n",
    "lasso.pred <- predict(lasso.mod,  newx = score_x )\n",
    "mse_score <- mean((lasso.pred - data_scoreMSE[, 1])^2)\n",
    "print(paste(\"MSE of real test data (12 month prediction): \", mse_score)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c76d1ce-fe4a-4ce7-80c5-de303641394d",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec59735-095a-4b30-ad6f-70ef123dbbf7",
   "metadata": {},
   "source": [
    "in this part, we use caret package to help conduct CV. Still,we use 70% train data to train RF model. <br>firstly, we apply CV method to choose best m and n.trees, and use the best tunes to train RF model. since the data is time series data, we use Sliding Window Cross-Validation<br>then use the trained model to predict test data and score data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f7ef962-0c2a-4343-9be8-acc881f740be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"total cv time 1.16389551957448\"\n"
     ]
    }
   ],
   "source": [
    "# 1 month prediction for RF model\n",
    "\n",
    "train_x = train_x_1\n",
    "train_y = train_y_1\n",
    "test_x = test_x_1\n",
    "test_y = test_y_1\n",
    "score_y = score_y_1\n",
    "\n",
    "train_data = train_data_1\n",
    "test_data = test_data_1\n",
    "data_scoreMSE = data_score_1\n",
    "\n",
    "\n",
    "# initialise a data.frame to store best tune M, and RMSE\n",
    "rftune <- data.frame()\n",
    "rftune$rmse <- c()\n",
    "rftune$mtry <- c()\n",
    "\n",
    "set.seed(1)\n",
    "\n",
    "\n",
    "star = Sys.time()\n",
    "\n",
    "# tuneGrid parameter only allowed 3 input \"mtry\" \"splitrule\" and 'min.node.size'\n",
    "# thus, we write a loop to find another best tune  'n.trees'.\n",
    "# we need to find best mtry and n.trees\n",
    "\n",
    "for (i in seq(1,5)){   \n",
    "train_control <- trainControl(method = \"timeslice\",\n",
    "              initialWindow = floor(0.7*nrow(train_x)),\n",
    "              horizon = 12,\n",
    "              skip = 3,\n",
    "              fixedWindow = TRUE,\n",
    "              allowParallel = TRUE)\n",
    "\n",
    "\n",
    "tuneGrid <- expand.grid(\n",
    "                       mtry =floor(ncol(train_x)/seq(1,10)), # best mtry\n",
    "                       splitrule= 'variance',\n",
    "                       min.node.size = 5) \n",
    "\n",
    "model <- train(train_x, train_y,\n",
    "   method = \"ranger\",\n",
    "   tuneGrid = tuneGrid,\n",
    "   trControl = train_control,\n",
    "   num.trees = 100*i  # best n.trees\n",
    "              );\n",
    "\n",
    "\n",
    "# save the best RMSE and mtry in every loop\n",
    "rftune[i,'rmse'] = min(model$results$RMSE)\n",
    "rftune[i,'mtry'] = model$bestTune$mtry\n",
    "}\n",
    "\n",
    "end = Sys.time()\n",
    "\n",
    "# cv time\n",
    "print(paste(\"total cv time\", end-star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77c1f1fe-7d71-4dda-bad8-8035302a0557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the 70% train data (1 month prediction):  4.67984766728327e-05\"\n",
      "[1] \"MSE of the rest 30% data (1 month prediction):  0.000665423885899809\"\n",
      "[1] \"MSE of real test data (1 month prediction):   32.1402803761187\"\n"
     ]
    }
   ],
   "source": [
    "best_rfmodel <- ranger(x= train_x, y = train_y,  \n",
    "                     data = train_data,  \n",
    "                     num.trees = 100*which.min(rftune$rmse),   #best tree number\n",
    "                     mtry = rftune[which.min(rftune$rmse),'mtry'],  #best mtry \n",
    "                     min.node.size = 5)\n",
    "#train mse\n",
    "predictions <- predict(best_rfmodel, data = train_data)\n",
    "mse <- mean((predictions$predictions - train_data[, 1])^2)\n",
    "print(paste(\"MSE of the 70% train data (1 month prediction): \", mse))\n",
    "\n",
    "\n",
    "#test mse\n",
    "predictions <- predict(best_rfmodel, data = test_data)\n",
    "mse <- mean((predictions$predictions - test_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 30% data (1 month prediction): \", mse))\n",
    "\n",
    "#score mse\n",
    "predictions <- predict(best_rfmodel, data = data_scoreMSE)\n",
    "mse <- mean((predictions$predictions - data_scoreMSE[, 1])^2)\n",
    "print(paste(\"MSE of real test data (1 month prediction):  \", mse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "967d08bc-81df-43f3-8e75-ca7fe726e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"total cv time 1.15544568697611\"\n"
     ]
    }
   ],
   "source": [
    "# 3 month prediction for RF model\n",
    "\n",
    "train_x = train_x_3\n",
    "train_y = train_y_3\n",
    "test_x = test_x_3\n",
    "test_y = test_y_3\n",
    "score_y = score_y_3\n",
    "\n",
    "train_data = train_data_3\n",
    "test_data = test_data_3\n",
    "data_scoreMSE = data_score_3\n",
    "\n",
    "\n",
    "# initialise a data.frame to store best tune M, and RMSE\n",
    "rftune <- data.frame()\n",
    "rftune$rmse <- c()\n",
    "rftune$mtry <- c()\n",
    "\n",
    "set.seed(1)\n",
    "\n",
    "star = Sys.time()\n",
    "\n",
    "# tuneGrid parameter only allowed 3 input \"mtry\" \"splitrule\" and 'min.node.size'\n",
    "# thus, we write a loop to find another best tune  'n.trees'.\n",
    "# we need to find best mtry and n.trees\n",
    "for (i in seq(1,5)){\n",
    "train_control <- trainControl(method = \"timeslice\",\n",
    "              initialWindow = floor(0.7*nrow(train_x)),\n",
    "              horizon = 12,\n",
    "              skip = 3,\n",
    "              fixedWindow = TRUE,\n",
    "              allowParallel = TRUE)\n",
    "\n",
    "\n",
    "tuneGrid <- expand.grid(\n",
    "                       mtry =floor(ncol(train_x)/seq(1,10)),\n",
    "                       splitrule= 'variance',\n",
    "                       min.node.size = 5) \n",
    "\n",
    "model <- train(train_x, train_y,\n",
    "   method = \"ranger\",\n",
    "   tuneGrid = tuneGrid,\n",
    "   trControl = train_control,\n",
    "   num.trees = 100*i);\n",
    "\n",
    "\n",
    "\n",
    "rftune[i,'rmse'] = min(model$results$RMSE)\n",
    "rftune[i,'mtry'] = model$bestTune$mtry\n",
    "}\n",
    "\n",
    "end = Sys.time()\n",
    "\n",
    "#cv time\n",
    "print(paste(\"total cv time\", end-star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e4e7682-6b1a-490a-aa94-a493a9d321eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the 70% train data (3 month prediction):  4.5714799646205e-05\"\n",
      "[1] \"MSE of the rest 30% data (3 month prediction):  0.00114464091725681\"\n",
      "[1] \"MSE of real test data (3 month prediction):   32.1440979979803\"\n"
     ]
    }
   ],
   "source": [
    "best_rfmodel <- ranger(x= train_x, y = train_y,   \n",
    "                     data = train_data,  \n",
    "                     num.trees = 100*which.min(rftune$rmse), #best tree number\n",
    "                     mtry = rftune[which.min(rftune$rmse),'mtry'], #best mtry\n",
    "                     min.node.size = 5)\n",
    "#train mse\n",
    "predictions <- predict(best_rfmodel, data = train_data)\n",
    "mse <- mean((predictions$predictions - train_data[, 1])^2)\n",
    "print(paste(\"MSE of the 70% train data (3 month prediction): \", mse))\n",
    "\n",
    "#test mse\n",
    "predictions <- predict(best_rfmodel, data = test_data)\n",
    "mse <- mean((predictions$predictions - test_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 30% data (3 month prediction): \", mse))\n",
    "\n",
    "#score mse \n",
    "predictions <- predict(best_rfmodel, data = data_scoreMSE)\n",
    "mse <- mean((predictions$predictions - data_scoreMSE[, 1])^2)\n",
    "print(paste(\"MSE of real test data (3 month prediction):  \", mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69d1894d-ce4f-4846-a751-2cebc4d11870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"total cv time 1.10922631025314\"\n"
     ]
    }
   ],
   "source": [
    "# 12 month prediction for RF model\n",
    "\n",
    "train_x = train_x_12\n",
    "train_y = train_y_12\n",
    "test_x = test_x_12\n",
    "test_y = test_y_12\n",
    "score_y = score_y_12\n",
    "\n",
    "train_data = train_data_12\n",
    "test_data = test_data_12\n",
    "data_scoreMSE = data_score_12\n",
    "\n",
    "\n",
    "# initialise a data.frame to store best tune M, and RMSE\n",
    "rftune <- data.frame()\n",
    "rftune$rmse <- c()\n",
    "rftune$mtry <- c()\n",
    "\n",
    "set.seed(1)\n",
    "\n",
    "star = Sys.time()\n",
    "\n",
    "# tuneGrid parameter only allowed 3 input: \"mtry\" \"splitrule\" and 'min.node.size'\n",
    "# thus, we write a loop to find another best tune  'n.trees'.\n",
    "# we need to find best mtry and n.trees\n",
    "for (i in seq(1,5)){\n",
    "train_control <- trainControl(method = \"timeslice\",\n",
    "              initialWindow = floor(0.7*nrow(train_x)),\n",
    "              horizon = 12,\n",
    "              skip = 3,\n",
    "              fixedWindow = TRUE,\n",
    "              allowParallel = TRUE)\n",
    "\n",
    "\n",
    "tuneGrid <- expand.grid(\n",
    "                       mtry =floor(ncol(train_x)/seq(1,10)),\n",
    "                       splitrule= 'variance',\n",
    "                       min.node.size = 5) \n",
    "\n",
    "model <- train(train_x, train_y,\n",
    "   method = \"ranger\",\n",
    "   tuneGrid = tuneGrid,\n",
    "   trControl = train_control,\n",
    "   num.trees = 100*i);\n",
    "\n",
    "\n",
    "\n",
    "rftune[i,'rmse'] = min(model$results$RMSE)\n",
    "rftune[i,'mtry'] = model$bestTune$mtry\n",
    "}\n",
    "\n",
    "end = Sys.time()\n",
    "\n",
    "print(paste(\"total cv time\", end-star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ed4f4be-a007-43d2-a99e-06788921ff67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the 70% train data (12 month prediction):  4.61976537009202e-05\"\n",
      "[1] \"MSE of the rest 30% data (12 month prediction):  0.000906436889446865\"\n",
      "[1] \"MSE of real test data (12 month prediction):   32.1377420462289\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_rfmodel <- ranger(x= train_x, y = train_y,   \n",
    "                     data = train_data,  \n",
    "                     num.trees = 100*which.min(rftune$rmse),  # best tree number\n",
    "                     mtry = rftune[which.min(rftune$rmse),'mtry'], #best mtry\n",
    "                     min.node.size = 5)\n",
    "# train mse\n",
    "predictions <- predict(best_rfmodel, data = train_data)\n",
    "mse <- mean((predictions$predictions - train_data[, 1])^2)\n",
    "print(paste(\"MSE of the 70% train data (12 month prediction): \", mse))\n",
    "\n",
    "# test mse\n",
    "predictions <- predict(best_rfmodel, data = test_data)\n",
    "mse <- mean((predictions$predictions - test_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 30% data (12 month prediction): \", mse))\n",
    "\n",
    "# score mse\n",
    "predictions <- predict(best_rfmodel, data = data_scoreMSE)\n",
    "mse <- mean((predictions$predictions - data_scoreMSE[, 1])^2)\n",
    "print(paste(\"MSE of real test data (12 month prediction):  \", mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4698dd25-ef84-48e9-8a02-0d8742cdb820",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2292ec-8ba1-407c-8a07-420dca8ac171",
   "metadata": {},
   "source": [
    "in this part, we use caret package to help conduct CV. Still,we use 70% train data to train RF model. <br>firstly, we apply CV method to choose best depth, n.trees and shrinkage, and use the best tunes to train GBRT model. since the data is time series data, we use Sliding Window Cross-Validation<br>then use the trained model to predict test data and score data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36416ac1-ae1f-488a-a16c-6ebcf364b485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.0008            -nan     0.1000    0.0001\n",
      "     2        0.0007            -nan     0.1000    0.0001\n",
      "     3        0.0006            -nan     0.1000    0.0001\n",
      "     4        0.0006            -nan     0.1000    0.0000\n",
      "     5        0.0005            -nan     0.1000    0.0000\n",
      "     6        0.0005            -nan     0.1000    0.0000\n",
      "     7        0.0005            -nan     0.1000    0.0000\n",
      "     8        0.0005            -nan     0.1000    0.0000\n",
      "     9        0.0004            -nan     0.1000    0.0000\n",
      "    10        0.0004            -nan     0.1000    0.0000\n",
      "    20        0.0003            -nan     0.1000    0.0000\n",
      "    40        0.0003            -nan     0.1000    0.0000\n",
      "    60        0.0002            -nan     0.1000    0.0000\n",
      "    80        0.0002            -nan     0.1000   -0.0000\n",
      "   100        0.0002            -nan     0.1000   -0.0000\n",
      "\n",
      "[1] \"total cv time 5.84427857398987\"\n",
      "   n.trees interaction.depth shrinkage n.minobsinnode\n",
      "20     100                 2       0.1             10\n"
     ]
    }
   ],
   "source": [
    "# 1 month predition of gradient Boosting\n",
    "train_x = train_x_1\n",
    "train_y = train_y_1\n",
    "test_x = test_x_1\n",
    "test_y = test_y_1\n",
    "score_y = score_y_1\n",
    "\n",
    "train_data = train_data_1\n",
    "test_data = test_data_1\n",
    "data_scoreMSE = data_score_1\n",
    "\n",
    "set.seed(1)\n",
    "\n",
    "\n",
    "star = Sys.time()\n",
    "train_control <- trainControl(method = \"timeslice\",\n",
    "              initialWindow = floor(0.7*nrow(train_x)),\n",
    "              horizon = 12,skip =3,\n",
    "              fixedWindow = TRUE,\n",
    "              allowParallel = TRUE)\n",
    "\n",
    "# generate a tune grid \n",
    "gbmGrid <- expand.grid(\n",
    "  interaction.depth = seq(1, 5),\n",
    "  n.trees = c(50,100,200),\n",
    "  shrinkage = c(0.01,0.1),\n",
    "  n.minobsinnode = 10\n",
    ")\n",
    "\n",
    "\n",
    "model <- train(train_x, train_y,\n",
    "   method = \"gbm\",\n",
    "   tuneGrid=gbmGrid,\n",
    "   trControl = train_control);\n",
    "\n",
    "end = Sys.time()\n",
    "\n",
    "\n",
    "print(paste(\"total cv time\", end-star))\n",
    "print(model$bestTune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af1ab74b-5933-486c-ab81-d77a4497ba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 100 trees...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the 70% train data (1 month prediction):  3.83555253806123e-06\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 100 trees...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the rest 30% data (1 month prediction):  0.000137858855899837\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 100 trees...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of real test data (1 month prediction):  31.5396936753651\"\n"
     ]
    }
   ],
   "source": [
    "gbm_model <- gbm(train_y ~ ., data = train_data, distribution = \"gaussian\", n.trees = model$bestTune$n.trees, interaction.depth = model$bestTune$interaction.depth,shrinkage = model$bestTune$shrinkage)\n",
    "\n",
    "# train mse\n",
    "predictions <- predict(gbm_model, newdata = train_data, type = \"response\")\n",
    "mse <- mean((predictions - train_data[, 1])^2)\n",
    "print(paste(\"MSE of the 70% train data (1 month prediction): \", mse))\n",
    "\n",
    "# test mse\n",
    "predictions <- predict(gbm_model, newdata = test_data, type = \"response\")\n",
    "mse <- mean((predictions - test_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 30% data (1 month prediction): \", mse))\n",
    "\n",
    "# score mse\n",
    "predictions <- predict(gbm_model, newdata = data_scoreMSE, type = \"response\")\n",
    "mse_score <- mean((predictions - data_scoreMSE[, 1])^2)\n",
    "print(paste(\"MSE of real test data (1 month prediction): \", mse_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "900e35a8-fe72-4c71-81b7-8a6ddc39fbfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.0008            -nan     0.1000    0.0001\n",
      "     2        0.0007            -nan     0.1000    0.0001\n",
      "     3        0.0006            -nan     0.1000    0.0001\n",
      "     4        0.0006            -nan     0.1000    0.0000\n",
      "     5        0.0005            -nan     0.1000    0.0000\n",
      "     6        0.0005            -nan     0.1000    0.0000\n",
      "     7        0.0005            -nan     0.1000    0.0000\n",
      "     8        0.0004            -nan     0.1000    0.0000\n",
      "     9        0.0004            -nan     0.1000    0.0000\n",
      "    10        0.0004            -nan     0.1000    0.0000\n",
      "    20        0.0003            -nan     0.1000    0.0000\n",
      "    40        0.0002            -nan     0.1000   -0.0000\n",
      "    50        0.0002            -nan     0.1000   -0.0000\n",
      "\n",
      "[1] \"total cv time 5.85430669784546\"\n",
      "   n.trees interaction.depth shrinkage n.minobsinnode\n",
      "22      50                 3       0.1             10\n"
     ]
    }
   ],
   "source": [
    "# 3 month predition of gradient Boosting\n",
    "train_x = train_x_3\n",
    "train_y = train_y_3\n",
    "test_x = test_x_3\n",
    "test_y = test_y_3\n",
    "score_y = score_y_3\n",
    "\n",
    "train_data = train_data_3\n",
    "test_data = test_data_3\n",
    "data_scoreMSE = data_score_3\n",
    "\n",
    "set.seed(3)\n",
    "\n",
    "star = Sys.time()\n",
    "train_control <- trainControl(method = \"timeslice\",\n",
    "              initialWindow = floor(0.7*nrow(train_x)),\n",
    "              horizon = 12,skip =3,\n",
    "              fixedWindow = TRUE,\n",
    "              allowParallel = TRUE)\n",
    "\n",
    "#generate a tune grid\n",
    "gbmGrid <- expand.grid(\n",
    "  interaction.depth = seq(1, 5),\n",
    "  n.trees = c(50,100,200),\n",
    "  shrinkage = c(0.01,0.1),\n",
    "  n.minobsinnode = 10\n",
    ")\n",
    "\n",
    "\n",
    "model <- train(train_x, train_y,\n",
    "   method = \"gbm\",\n",
    "   tuneGrid=gbmGrid,\n",
    "   trControl = train_control);\n",
    "end = Sys.time()\n",
    "\n",
    "print(paste(\"total cv time\", end-star))\n",
    "print(model$bestTune)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0f0106b-16ad-4631-98d8-8764adaa11bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 50 trees...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the 70% train data (3 month prediction):  6.57179339492043e-06\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 50 trees...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the rest 30% data (3 month prediction):  0.000131966284237335\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 50 trees...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of real test data (3 month prediction):  31.558880838485\"\n"
     ]
    }
   ],
   "source": [
    "gbm_model <- gbm(train_y ~ ., data = train_data, distribution = \"gaussian\", n.trees = model$bestTune$n.trees, interaction.depth = model$bestTune$interaction.depth,shrinkage = model$bestTune$shrinkage)\n",
    "\n",
    "# train mse\n",
    "predictions <- predict(gbm_model, newdata = train_data, type = \"response\")\n",
    "mse <- mean((predictions - train_data[, 1])^2)\n",
    "print(paste(\"MSE of the 70% train data (3 month prediction): \", mse))\n",
    "\n",
    "# test mse\n",
    "predictions <- predict(gbm_model, newdata = test_data, type = \"response\")\n",
    "mse <- mean((predictions - test_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 30% data (3 month prediction): \", mse))\n",
    "\n",
    "# score mse\n",
    "predictions <- predict(gbm_model, newdata = data_scoreMSE, type = \"response\")\n",
    "mse_score <- mean((predictions - data_scoreMSE[, 1])^2)\n",
    "print(paste(\"MSE of real test data (3 month prediction): \", mse_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0205114-536b-453c-8d0a-65518536e2fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.0008            -nan     0.1000    0.0001\n",
      "     2        0.0007            -nan     0.1000    0.0001\n",
      "     3        0.0007            -nan     0.1000    0.0000\n",
      "     4        0.0007            -nan     0.1000    0.0000\n",
      "     5        0.0006            -nan     0.1000    0.0000\n",
      "     6        0.0006            -nan     0.1000    0.0000\n",
      "     7        0.0006            -nan     0.1000    0.0000\n",
      "     8        0.0006            -nan     0.1000    0.0000\n",
      "     9        0.0005            -nan     0.1000    0.0000\n",
      "    10        0.0005            -nan     0.1000    0.0000\n",
      "    20        0.0004            -nan     0.1000    0.0000\n",
      "    40        0.0003            -nan     0.1000    0.0000\n",
      "    60        0.0003            -nan     0.1000   -0.0000\n",
      "    80        0.0003            -nan     0.1000   -0.0000\n",
      "   100        0.0003            -nan     0.1000   -0.0000\n",
      "\n",
      "[1] \"total cv time 22.9334223270416\"\n",
      "   n.trees interaction.depth shrinkage n.minobsinnode\n",
      "17     100                 1       0.1             10\n"
     ]
    }
   ],
   "source": [
    "# 12 month predition of gradient Boosting\n",
    "train_x = train_x_12\n",
    "train_y = train_y_12\n",
    "test_x = test_x_12\n",
    "test_y = test_y_12\n",
    "score_y = score_y_12\n",
    "\n",
    "train_data = train_data_12\n",
    "test_data = test_data_12\n",
    "data_scoreMSE = data_score_12\n",
    "\n",
    "set.seed(12)\n",
    "\n",
    "star = Sys.time()\n",
    "train_control <- trainControl(method = \"timeslice\",\n",
    "              initialWindow = floor(0.7*nrow(train_x)),\n",
    "              horizon = 12,sk\n",
    "              fixedWindow = TRUE,\n",
    "              allowParallel = TRUE)\n",
    "\n",
    "#tune grid\n",
    "gbmGrid <- expand.grid(\n",
    "  interaction.depth = seq(1, 5),\n",
    "  n.trees = c(50,100,200),\n",
    "  shrinkage = c(0.01,0.1),\n",
    "  n.minobsinnode = 10\n",
    ")\n",
    "\n",
    "\n",
    "model <- train(train_x, train_y,\n",
    "   method = \"gbm\",\n",
    "   tuneGrid=gbmGrid,\n",
    "   trControl = train_control);\n",
    "end = Sys.time()\n",
    "\n",
    "\n",
    "print(paste(\"total cv time\", end-star))\n",
    "print(model$bestTune)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2a14d45-2ff6-485f-99f8-b59d28e542c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 100 trees...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the 70% train data (12 month prediction):  6.60612864759031e-06\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 100 trees...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of the rest 30% data (12 month prediction):  0.000129689456290248\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 100 trees...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"MSE of real test data (12 month prediction):  31.541134467644\"\n"
     ]
    }
   ],
   "source": [
    "gbm_model <- gbm(train_y ~ ., data = train_data, distribution = \"gaussian\", n.trees = model$bestTune$n.trees, interaction.depth = model$bestTune$interaction.depth,shrinkage = model$bestTune$shrinkage)\n",
    "\n",
    "# train mse\n",
    "predictions <- predict(gbm_model, newdata = train_data, type = \"response\")\n",
    "mse <- mean((predictions - train_data[, 1])^2)\n",
    "print(paste(\"MSE of the 70% train data (12 month prediction): \", mse))\n",
    "\n",
    "#test mse\n",
    "predictions <- predict(gbm_model, newdata = test_data, type = \"response\")\n",
    "mse <- mean((predictions - test_data[, 1])^2)\n",
    "print(paste(\"MSE of the rest 30% data (12 month prediction): \", mse))\n",
    "\n",
    "#score mse\n",
    "predictions <- predict(gbm_model, newdata = data_scoreMSE, type = \"response\")\n",
    "mse_score <- mean((predictions - data_scoreMSE[, 1])^2)\n",
    "print(paste(\"MSE of real test data (12 month prediction): \", mse_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
